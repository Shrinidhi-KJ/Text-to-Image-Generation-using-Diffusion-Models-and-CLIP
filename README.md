# Text-to-Image-Generation-using-Diffusion-Models-and-CLIP
This project implements a Text-to-Image generation pipeline using diffusion models, VAE, and CLIP. It supports generating images from text prompts or transforming input images with added noise. Key features include Classifier-Free Guidance (CFG), VAE-based encoding/decoding, and text conditioning with CLIP for high-quality image synthesis
